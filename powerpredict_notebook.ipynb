{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a877514d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Powerpredict\" data-toc-modified-id=\"Powerpredict-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Powerpredict</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-dataset\" data-toc-modified-id=\"Loading-the-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading the dataset</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19de1db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ca6ee4668e616e8c636c841135fc98b",
     "grade": false,
     "grade_id": "cell-e73d576a3d47c12f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Powerpredict\n",
    "\n",
    "Daily power consumption is related to the weather (rain, sunshine, temperature, etc). \n",
    "Prediction of the power consumption based on the weather is relevant for energy suppliers.\n",
    "In this dataset you have to use the provided weather information to predict the power consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82629fa3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "748858e67ed9a5f851fab7f8157501b6",
     "grade": false,
     "grade_id": "cell-feda725da2aaae3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6c916",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1db565d3db51423f00b2ac5ad38a89f5",
     "grade": false,
     "grade_id": "cell-c976be14db699e69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# select \"0\" for Random Forests and \"1\" for Linear Regression\n",
    "MACHINE_LEARNING_MODEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc82529",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bd8394a54af19a99971caee89ca239d",
     "grade": false,
     "grade_id": "cell-49574214f7b79ad7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \".\"\n",
    "if os.path.exists(\"/data/mlproject22\"):\n",
    "    DATASET_PATH = \"/data/mlproject22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f91858",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce8f3ea766d895e3706f74e677a9d90c",
     "grade": false,
     "grade_id": "cell-0daa894d901175e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "powerpredict = pd.read_csv(os.path.join(DATASET_PATH,\"powerpredict.csv.zip\"))\n",
    "X = powerpredict.drop(columns=[\"power_consumption\"])\n",
    "y = powerpredict[[\"power_consumption\"]]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09a069",
   "metadata": {},
   "source": [
    "Some columns are dropped here for simplicity, but they might provide useful information as well, so you might want to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af519c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_object_columns(df):\n",
    "    drop_cols = [c for t, c in zip([t !=\"object\" for t in df.dtypes], df.columns) if not t]\n",
    "    return df.drop(columns=drop_cols)\n",
    "\n",
    "DOC = drop_object_columns\n",
    "\n",
    "def predict_show_metrics(name, reg, metric):\n",
    "    print(f\"{name}\", metric(y, reg.predict(DOC(x_filtered))))\n",
    "\n",
    "    \n",
    "def visualize_data():\n",
    "    temperature_columns = ['Bedrock_t', 'Gotham City_t', 'New New York_t', 'Paperopoli_t', 'Springfield_t']\n",
    "    # first plot with temps\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for col in temperature_columns:\n",
    "        plt.plot(powerpredict[col], label=col)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Temperature\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # second plot with power consumption\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(powerpredict['power_consumption'])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Power Consumption')\n",
    "    plt.title('Power Consumption')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3893ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forests estimator\n",
    "\n",
    "le = preprocessing.OrdinalEncoder()\n",
    "# Buidling the Model:\n",
    "# 1. Preproccesing of data\n",
    "selected_features = ['Bedrock_t', 'Bedrock_t_low', 'Bedrock_humidity',\n",
    "                     'Bedrock_wind_deg', 'Bedrock_clouds', 'Gotham City_t',\n",
    "                     'Gotham City_t_high', 'Gotham City_bars', 'Gotham City_humidity',\n",
    "                     'Gotham City_wind_speed', 'Gotham City_wind_deg', 'Gotham City_clouds',\n",
    "                     'New New York_t', 'New New York_t_low', 'New New York_t_high',\n",
    "                     'New New York_bars', 'New New York_humidity', 'New New York_wind_speed',\n",
    "                     'New New York_wind_deg', 'Paperopoli_t', 'Paperopoli_t_low',\n",
    "                     'Paperopoli_t_high', 'Paperopoli_bars', 'Paperopoli_humidity',\n",
    "                     'Paperopoli_wind_deg', 'Paperopoli_weather_description',\n",
    "                     'Springfield_t', 'Springfield_t_low', 'Springfield_t_high',\n",
    "                     'Springfield_bars', 'Springfield_humidity', 'Springfield_wind_deg']\n",
    "\n",
    "\n",
    "data = powerpredict[selected_features]\n",
    "data = data.dropna()\n",
    "data = le.fit_transform(data)\n",
    "\n",
    "random_forest_regressor_model = RandomForestRegressor(max_features='log2', criterion='squared_error', max_depth=17, n_jobs=(-1), n_estimators=50, verbose=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(data, y, random_state=42,test_size=0.1)\n",
    "\n",
    "random_forest_regressor_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# store the model:\n",
    "from joblib import dump, load\n",
    "dump(random_forest_regressor_model, 'random_forests_model.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116c5bd",
   "metadata": {},
   "source": [
    "Here is an example dummy ML method showing the success of such a simple predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.OrdinalEncoder()\n",
    "\n",
    "# Encode the data without the first row\n",
    "encoded_data = encoder.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame with the encoded data\n",
    "data = pd.DataFrame(encoded_data)\n",
    "\n",
    "# Fill NaN values with mean\n",
    "mean_value = data.mean()\n",
    "data = data.fillna(mean_value)\n",
    "\n",
    "allData = pd.concat([data, y], axis=1)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = allData.corr()\n",
    "\n",
    "# Get the most correlated features and throw away the ones that don't have enough correlation\n",
    "power_cons_corr = (\n",
    "    correlation_matrix[\"power_consumption\"].abs().sort_values(ascending=False)\n",
    ")\n",
    "selected_columns = power_cons_corr[1:21].index.tolist()\n",
    "x_filtered = allData[selected_columns]\n",
    "\n",
    "# split the set into train and test set\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    x_filtered, y, test_size=0.20, random_state=22\n",
    ")\n",
    "# Linear regression\n",
    "lin = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "lin.fit(X_train, y_train)\n",
    "y_predicted = lin.predict(X_test)\n",
    "y_predicted_train = lin.predict(X_train)\n",
    "from joblib import dump, load\n",
    "dump(lin, 'linear_regression.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8d48f",
   "metadata": {},
   "source": [
    "You have to implement a simple method that performs the predictions with the given signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684b5f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ca0f06f2b89b9d383e756b2058b9899",
     "grade": false,
     "grade_id": "cell-88aee4a03bbf8d46",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# start by preprocessing the data\n",
    "le = preprocessing.OrdinalEncoder()\n",
    "\n",
    "selected_features = ['Bedrock_t', 'Bedrock_t_low', 'Bedrock_humidity',\n",
    "                         'Bedrock_wind_deg', 'Bedrock_clouds', 'Gotham City_t',\n",
    "                         'Gotham City_t_high', 'Gotham City_bars', 'Gotham City_humidity',\n",
    "                         'Gotham City_wind_speed', 'Gotham City_wind_deg', 'Gotham City_clouds',\n",
    "                         'New New York_t', 'New New York_t_low', 'New New York_t_high',\n",
    "                         'New New York_bars', 'New New York_humidity', 'New New York_wind_speed',\n",
    "                         'New New York_wind_deg', 'Paperopoli_t', 'Paperopoli_t_low',\n",
    "                         'Paperopoli_t_high', 'Paperopoli_bars', 'Paperopoli_humidity',\n",
    "                         'Paperopoli_wind_deg', 'Paperopoli_weather_description',\n",
    "                         'Springfield_t', 'Springfield_t_low', 'Springfield_t_high',\n",
    "                         'Springfield_bars', 'Springfield_humidity', 'Springfield_wind_deg']\n",
    "\n",
    "def leader_board_predict_fn(values):\n",
    "    \n",
    "    \n",
    "    if MACHINE_LEARNING_MODEL == 0:\n",
    "        values_selected = values[selected_features]\n",
    "        values_selected = values_selected.dropna()\n",
    "        values_encoded = le.fit_transform(values_selected)\n",
    "        from joblib import dump, load\n",
    "        loaded_rfr = load('random_forests_model.joblib') \n",
    "        return loaded_rfr.predict(values_encoded)\n",
    "    if MACHINE_LEARNING_MODEL == 1:\n",
    "        try:\n",
    "            values = le.fit_transform(values)\n",
    "            # only get the most features that were mostly correlated to the model\n",
    "            values_filtered = values[:, selected_columns]\n",
    "            \n",
    "            from joblib import dump, load\n",
    "            loaded_rfr = load('linear_regression.joblib')  # Provide the file path to the saved model\n",
    "            return loaded_rfr.predict(values_filtered)\n",
    "        except Exception as E:\n",
    "            print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21185cf9",
   "metadata": {},
   "source": [
    "which will then be used to calculate the leaderboard score in a way similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea36af6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c2ab6ceef67d36f163c25a1edef8c31",
     "grade": true,
     "grade_id": "cell-21081c123b418d33",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_score():\n",
    "    \"\"\"\n",
    "    Function to compute scores for train and test datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    import sklearn.metrics\n",
    "    import pandas as pd\n",
    "    import pathlib\n",
    "    import os\n",
    "\n",
    "    try:\n",
    "        TEST_DATASET_PATH = \".\"\n",
    "        if os.path.exists(\"/data/mlproject22/\"):\n",
    "            TEST_DATASET_PATH = \"/data/mlproject22/\"\n",
    "\n",
    "        test_data = pd.read_csv(os.path.join(TEST_DATASET_PATH,\"powerpredict.csv.zip\"))\n",
    "        X_test = test_data.drop(columns=[\"power_consumption\"])\n",
    "        y_test = test_data[[\"power_consumption\"]]\n",
    "        y_predicted = leader_board_predict_fn(X_test)\n",
    "        dataset_score = sklearn.metrics.mean_absolute_error(y_test, y_predicted)\n",
    "    except Exception:\n",
    "        dataset_score = float(\"nan\")\n",
    "    print(f\"Train Dataset Score: {dataset_score}\")\n",
    "\n",
    "    import os\n",
    "    import pwd\n",
    "    import time\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "    user_id = pwd.getpwuid( os.getuid() ).pw_name\n",
    "    curtime = time.time()\n",
    "    dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    try:  \n",
    "        HIDDEN_DATASET_PATH = os.path.expanduser(\"/data/mlproject22-test-data/\")\n",
    "        test_data = pd.read_csv(os.path.join(HIDDEN_DATASET_PATH,\"hidden_powerpredict.csv.zip\"))\n",
    "        X_test = test_data.drop(columns=[\"power_consumption\"])\n",
    "        y_test = test_data[[\"power_consumption\"]]\n",
    "        y_predicted = leader_board_predict_fn(X_test)\n",
    "        hiddendataset_score = sklearn.metrics.mean_absolute_error(y_test, y_predicted)\n",
    "        print(f\"Test Dataset Score: {hiddendataset_score}\")\n",
    "        score_dict = dict(\n",
    "            score_hidden=hiddendataset_score,\n",
    "            score_train=dataset_score,\n",
    "            unixtime=curtime,\n",
    "            user=user_id,\n",
    "            dt=dt_now,\n",
    "            comment=\"\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        err = str(e)\n",
    "        score_dict = dict(\n",
    "            score_hidden=float(\"nan\"),\n",
    "            score_train=dataset_score,\n",
    "            unixtime=curtime,\n",
    "            user=user_id,\n",
    "            dt=dt_now,\n",
    "            comment=err\n",
    "        )\n",
    "\n",
    "    #if list(pathlib.Path(os.getcwd()).parents)[0].name == 'source':\n",
    "    #    print(\"we are in the source directory... replacing values.\")\n",
    "    #    print(pd.DataFrame([score_dict]))\n",
    "    #    score_dict[\"score_hidden\"] = -1\n",
    "    #    score_dict[\"score_train\"] = -1\n",
    "    #    print(\"new values:\")\n",
    "    #    print(pd.DataFrame([score_dict]))\n",
    "\n",
    "    pd.DataFrame([score_dict]).to_csv(\"powerpredict.csv\", index=False)\n",
    "    \n",
    "get_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "352px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
